num_layer: 6
num_attention_head: 8
hidden_dropout_prob: 0
ffn_dim: 768
activation: 'relu'

projection_dim: 384
hidden_dim: 384